[["index.html", "Biostatistics Portfolio I Preface", " Biostatistics Portfolio I Dr. F.J. Rodenburg © 2020–2022 Universiteit Leiden Preface Teaching statistics to students of the life sciences is a challenge: The courses are usually too short, with too much time in between them; Too many skills are introduced at once (math, programming and statistics); The connection to other courses is not clear enough. This is what I aim to address through this portfolio. You should complete the chapters leading up to your first statistics course. Part II will then pick up where your first course (presumably) left off and is meant to bridge the gap between your first statistics course and the next. Figure 0.1: The knowledge that is usually either assumed to be known already, or introduced briefly at that start of your first statistics course, will be introduced gradually throughout this portfolio.1 Chapters are short, have overlap with each other, and are accompanied with explanatory videos. This is not meant to be a cumbersome addition to your already intensive education, it is merely meant to reduce the difficulty of statistics courses. For those seeking an extra challenge, there are optional exercises that go more in-depth. Expert knowledge is what you learn during your other courses. Many choices in statistics are driven by knowledge of the subject area (e.g. biology). This holds especially true for study design and model selection.↩︎ "],["installation.html", "Chapter 1 Installation 1.1 Installation Guide 1.2 The RStudio interface", " Chapter 1 Installation Date: Start of the year, during the basic mathematics course. Topic: Programming Duration: 30–60 min. Throughout this portfolio, we will use RStudio. To use RStudio, you need to install both R and RStudio. (Even if you have an existing version, I recommend getting the latest version using the guide below.) 1.1 Installation Guide If you’re comfortable with computer software, it boils down to: Install R; Install RStudio; Open RStudio and try to knit a template R markdown file. If you can’t knit to PDF, see the note below and try knitting to HTML instead. Note about TinyTeX TinyTeX is not required for the portfolio. With TinyTeX, you can knit to PDF. This has several advantages over HTML and Word, which are explained in the second video. For the portfolio, all you need is a working version of RStudio, and to be able to knit to Word. Note about installation problems Address installation issues early on. If you’re following this portfolio in the context of your biology education at Leiden University, you can always contact Dr. H.G.J. van Mil or me about installation issues. Otherwise, see the general tips below, or try asking a question on Stackoverflow. Some general tips that will save you a lot of headaches with software during your education: Setting your system language to English (Windows, Mac) makes everything a lot easier to find; If you store data in Excel, setting the decimal separator to a dot (.) instead of a comma (,) will also save you a lot of extra effort; If you are on Windows, I highly recommend working on an account with administrator rights and setting user account control to “Never notify”. (Link says Windows 7 &amp; 8, but it works the same for Windows 10.) 1.2 The RStudio interface Watch the video on the RStudio interface below. Question: As a simple checklist, see if you can do the following: Create a new R markdown file; Delete everything that is not the preamble; Create a new code chunk and write some simple code like 1 + 1; Run the code. Try to knit the document to HTML, Word or PDF. From here on I will assume basic familiarity with the RStudio interface. "],["basic-programming-tutorials.html", "Chapter 2 Basic Programming Tutorials 2.1 swirl 2.2 learnr (*)", " Chapter 2 Basic Programming Tutorials Date: Start of the year, during the basic mathematics course. Topic: Programming Duration: 30–90 min. There are two great tutorial for learning the basics in R. This video shows how to use them: 2.1 swirl Watch the part about swirl and complete chapters 1, 2, 4, 7 &amp; 8 from the R Programming course. 2.2 learnr (*) Complete the Data Basics chapter from the learnr package as explained in the video. (If you don’t see a Tutorial tab, run install.packages(\"learnr\") in the console and then restart RStudio.) From here on out, I will assume basic familiarity with R syntax. If you can use R as a glorified calculator, that is enough for now. "],["mendelian-genetics.html", "Chapter 3 Mendelian Genetics 3.1 Corn Example 3.2 Chi-Squared Test", " Chapter 3 Mendelian Genetics Date: 21/22 September 2021 Topic: Probability theory, hypothesis testing Duration: 30–90 min. In this chapter you will learn how to compare observed to expected frequencies using a chi-squared test. 3.1 Corn Example In the basic practicals you will count the number of differently colored corn kernels. Figure 3.1: A cob of corn with differently colored kernels. According to Mendelian genetics, if both parents were heterozygous for one color-causing gene, then we would expect a \\(3 : 1\\) ratio of kernels with dominant to recessive trait. For example, consider heterozygous parents for the red color-causing gene R: Table 3.1: Crossing of two heterozygous parents. R r R RR (red) Rr (red) r Rr (red) rr (yellow) If both parents were indeed Rr, then we would expected \\(\\text{red} : \\text{yellow} = 3 : 1\\) in the offspring. A statistical test works by taking on a statement of no difference and then collecting evidence against it. For the chi-squared test, that means that we compare the observed frequencies to the frequencies we would get under a \\(3:1\\) ratio. You can calculate these expected frequencies simply by multiplying the total kernels counted with the expected proportion. (Take care to convert the ratio to a proportion first.) Exercise 1 Suppose you count \\(361\\) red kernels and \\(139\\) yellow ones. What are the expected number of red and yellow kernels under the null-hypothesis of a \\(3 : 1\\) ratio? Exercise 2 The chi-squared test is defined as follows: \\[\\begin{equation} \\displaystyle\\chi^2 = \\sum_{i = 1}^k \\frac{(\\text{observed}_i - \\text{expected}_i)^2}{\\text{expected}_i} \\tag{3.1} \\end{equation}\\] Where \\(k\\) is the number of groups. Since there are only two groups (red, yellow), this becomes: \\(\\displaystyle\\chi^2 = \\frac{(\\text{observed}_\\text{red} - \\text{expected}_\\text{red})^2}{\\text{expected}_\\text{red}} + \\frac{(\\text{observed}_\\text{yellow} - \\text{expected}_\\text{yellow})^2}{\\text{expected}_\\text{yellow}}\\) Calculate \\(\\chi^2\\) using the observed and expected numbers from exercise 1. Show your calculation. 3.2 Chi-Squared Test In R you can compare observed to expected frequencies using chisq.test: example &lt;- c(361, 139) chisq.test(example, p = c(3/4, 1/4)) # Test against a 3:1 ratio ## ## Chi-squared test for given probabilities ## ## data: example ## X-squared = 2.0907, df = 1, p-value = 0.1482 This test calculates \\(\\chi^2\\) and computes a corresponding \\(p\\)-value that has the following meaning: If the population has a \\(3 : 1\\) ratio of red to yellow kernels, what is the chance of observing at least this large a deviation?2 If this chance is very small, then perhaps the null-hypothesis of a \\(3 : 1\\) ratio is not realistic and we reject it. If it is large, then this corn cob might as well have arisen from parents that yield a \\(3 : 1\\) ratio, and we don’t reject the null-hypothesis. So what is small and large? That is a matter of opinion, but in biology a value of \\(0.05\\) is often used as a boundary. That means there is a \\(\\frac{1}{20}\\) chance of incorrectly concluding a significant deviation from \\(3 : 1\\). Exercise 3 Look at the output from the chi-squared test. With a threshold of \\(0.05\\), would you reject the null-hypothesis? What do you conclude? Exercise 4 Perform the same \\(\\chi^2\\)-test for your own counts of a corn cob and report the conclusion. Use the code from the example and adapt it for your own counts. Exercise 5 (optional) In the basic practicals, it was explained that all of four different dominant mutations are required for there to be red kernels: C, R, A1 and A2. Since these are all dominant mutations, let’s assume that each mutant protein has a \\(\\frac{3}{4}\\) chance of being present in the offspring (due to a \\(3 : 1\\) ratio). What is then the chance of a red kernel? (For simplicity, ignore the possibility of C-inhibitor.) Population here does not refer to a biological population, but a statistical population. It is the population of all possible red and yellow corn kernels that could have formed from a \\(3 : 1\\) ratio.↩︎ "],["bradford-assay.html", "Chapter 4 Bradford Assay 4.1 What Is a Bradford Assay? 4.2 How to Contruct a BSA-Curve in R 4.3 Using a Bradford Assay for Estimation 4.4 How Precise Is the Estimate? 4.5 Improving Your Figure (*) 4.6 Alternative Method (*)", " Chapter 4 Bradford Assay Date: 2/3 November 2021 Topic: Estimation, Prediction Duration: 30–90 min. In this chapter you will learn how to conduct a Bradford assay for estimating the amount of protein present in a sample. From this chapter on, you will collect all your analyses into a portfolio. This is simply an R markdown file that you knit to Word at the end of each chapter. At the start of the statistics course at the end of the academic year, your portfolio should contain all the exercises of chapters 4–6. Remember, to make a new R markdown file, go to File &gt; New File &gt; R markdown. Then select Word and press OK. 4.1 What Is a Bradford Assay? In the basic practicals you will use a spectrophotometer to measure light passing through a sample with a known protein concentration. By doing so for various concentrations of protein, you can construct a curve for the amount of protein present in a sample, given the amount of light passing through. This is a basic tool in biological experimentation. The protein used as a reference to construct the curve is called Bovine Serum Albumin (BSA).3 Hence the name: BSA curve. Table 4.1: Example data of a BSA experiment. As more protein is present in the sample, less light passes through and so the \\(\\text{A}_{595}\\) increases. BSA \\((\\mu\\text{g})\\) Absorption \\((\\text{A}_{595})\\) 0 0.000 1 0.135 2 0.235 3 0.328 4 0.409 5 0.495 Figure 4.1: A typical BSA curve, constructed from the data in table 4.1. In the first part of this assignment, you will construct a BSA-curve based on your experimental data. In the second half, we are going to express the uncertainty of the estimation. 4.2 How to Contruct a BSA-Curve in R As an example, I will show you how to construct a BSA curve from the data shown in table 4.1. 4.2.1 Enter your data First we create a data frame containing the BSA amounts and the observed \\(\\text{A}_{595}\\) values. BSA &lt;- 0:5 A595 &lt;- c(0, 0.135, 0.235, 0.328, 0.409, 0.495) DF &lt;- data.frame(BSA, A595) This will create an object DF in the object space. You can view it by clicking on it in the environment tab of the upper-right pane in RStudio. 4.2.2 Fit a Simple Linear Model Watch the first two minutes of this video on simple linear regression. Question: A Bradford assay shows a [positive / negative] linear relationship between the amount of protein and the absorbance. (Choose one.) Describe in your own words what intercept &amp; slope mean. Enter your data in R as shown above, using your own experimental data. Estimate the intercept and slope as follows: model &lt;- lm(A595 ~ BSA, data = DF) How that works will be explained in the statistics course. For now, let’s extract the intercept and slope from this model: coef(model) ## (Intercept) BSA ## 0.02485714 0.09685714 In this example, the estimated line pretty much goes through the origin,4 with an intercept of about 0.02. We can also see that there is a positive linear relationship between the amount of BSA and the absorbance: For every microgram of BSA added, the absorbance increases by about 0.1. Question: What are the intercept and slope of your experimental data? 4.2.3 Plot your data &amp; draw a line Finally we create a plot and add a line as follows: plot(A595 ~ BSA, data = DF) abline(coef(model)) As you can see in the example here, though it looks a bit basic, this is all you need to produce a BSA curve. Of course you can improve your figure if you want, by using more advanced plotting routines. Question: Create the plot shown above using your own experimental data. 4.3 Using a Bradford Assay for Estimation Let’s say you measured the absorbance of the sample of interest and ended up with a value of \\(\\text{A}_{595} = 0.264\\). Using the BSA curve, you can estimate the amount of protein as shown in the figure below: Figure 4.2: To estimate the amount of protein, look at the \\(\\text{A}_{595}\\) on the y-axis, then see which position it corresponds to on the x-axis. Apparently the sample of interest has the same absorbance as a BSA sample of about \\(2.5\\) microgram. If you want a more precise estimate, you have to use the equation of the model we just fitted: \\[\\begin{equation} \\text{A}_{595} = \\text{intercept} + \\text{slope}\\times\\text{BSA} \\tag{4.1} \\end{equation}\\] If we fill in the example, we get: \\[ \\begin{aligned} 0.264 &amp;= 0.02485714 + 0.09685714 \\times \\text{BSA} + 0 \\\\ \\\\ \\text{BSA} &amp;= \\frac{0.264 - 0.02485714}{0.09685714} \\approx 2.47 \\end{aligned} \\] Which is approximately equal to the \\(2.5\\) we read from figure 4.2. Question: Can you read from your own figure the amount of protein in the sample of interest? Perform the estimation using eq. (4.1) with your own BSA curve and your own observed absorbance: If you have performed the experiment twice or more, you can average the absorbance for a more precise answer; Make sure to adjust for any dilution you applied to the sample. 4.4 How Precise Is the Estimate? I’m sure you’ve noticed that the observations do not exactly fall on the line. The regression model is but an approximation of the true relationship. This is caused by many things: No matter how careful you are, the amount of BSA cannot be weighed exactly; The spectrophotometer does not have infinite precision; Any dilutions applied can introduce small errors; The true relationship is probably not perfectly linear. It is more than likely that if you perform the experiment again, you will obtain slightly different values. Even if you take great care, there is always uncertainty. At best, you can keep that uncertainty low. So how much uncertainty is there? How do we express that? Below I will discuss a simple measure to include in your plot, and a great way to visualize the uncertainty. 4.4.1 R-squared \\(R^2\\) is the amount of variance explained by the model. In other words: How much of the total variance in \\(\\text{A}_{595}\\) can be explained by the line? The red segments on the right represent the original spread in \\(\\text{A}_{595}\\),5 and on the right we see the spread that is left after accounting for our model. You can clearly see that the distances on the right are much smaller than on the left. If you square these segments and sum them, that is called the variance. \\(R^2\\) is then calculated as: \\[R^2 = 1 - \\frac{\\text{remaining variance}}{\\text{total variance}}\\] R includes this value in the summary of a linear model by default. You can obtain it as follows: summary(model)$r.squared ## [1] 0.9913461 Apparently the BSA curve explains around \\(99.1\\%\\) of the total variance in absorbance. This is quite a large amount: Only \\(0.9\\%\\) of the variance is unexplained. A higher \\(R^2\\) value means there is less uncertainty. Question: What is the value of \\(R^2\\) using your own experimental data? How could you obtain a higher \\(R^2\\)? 4.4.2 Prediction interval Where would you expect 95% of the future observations of \\(\\text{A}_{595}\\) to be? That is the question a 95% prediction interval answers. Though its calculation is beyond the scope of this chapter, generating such an interval along the BSA curve in R can be done in a few lines of code: plot(A595 ~ BSA, data = DF) abline(coef(model)) newX &lt;- data.frame(BSA = seq(0, 5, 0.1)) # 0.0, 0.1, ..., 4.9, 5.0 newY &lt;- data.frame(predict(model, newX, interval = &quot;predict&quot;)) newDF &lt;- cbind(newX, newY) lines(lwr ~ BSA, data = newDF) # lower bound of the interval lines(upr ~ BSA, data = newDF) # upper bound of the interval Question: Produce a prediction interval for your own BSA curve? Try it by copying the code above and adjusting it if you like. Figure 4.2 showed how to estimate the protein concentration of a sample of interest. Now that you have a prediction interval around the line, within which values do you expect the protein concentration to be? 4.5 Improving Your Figure (*) In the examples so far, I tried to keep the coding part simple. Here I will show how to reproduce the figure by expanding the code a bit. You can use whichever parts you like and change it. Using a hashtag (#), I will provide comments after each line to explain what it’s for. For additional tips on improving figures and adding them to your portfolio, see the chapter on adding figures. 4.5.1 Improving the main plot Using some tricks described in the help page of plotmath, you can add proper annotation to your axes: plot( A595 ~ BSA, data = DF, # A595 vs BSA, from data set DF main = &quot;BSA Curve&quot;, # Title xlab = &quot;Protein (μg/ml)&quot;, # X-axis annotation ylab = bquote(A[595]), # Y-axis annotation pch = 19, # Solid point character (see ?pch) las = 1 # Set label style to horizontal ) 4.5.2 Highlighting the line For emphasis, I changed the width and color of the line: # Add this *after* your call to the plot function. Then run both. abline( coef(model), # Coefficients from the object &#39;model&#39; lwd = 2, # Increase line width to 2 (default 1) col = &quot;steelblue&quot; # Change the color of the line ) 4.5.3 Adding a grid You can add a grid if you like. If you do, keep these three things in mind: Don’t use grid. This function is so dumb even its help page admits you’re better off using abline(h = ..., v = ...): Figure 4.3: Look closely at how the grid meets the axes on the left… # Bad example: plot(A595 ~ BSA, data = DF, main = &quot;wow great job, grid...&quot;) grid(nx = 5, ny = 5) abline(coef(model)) # Good example: plot(A595 ~ BSA, data = DF, main = &quot;abline to the rescue&quot;) abline(h = seq(0, 0.5, 0.1), v = 0:5, col = &quot;lightgray&quot;) abline(coef(model)) Some prefer light on dark, others dark on light. I don’t mind either way. But avoid using a high contrast for your grid. It is not the main subject being plotted and should fall into the background: Figure 4.4: A grid should have low contrast to avoid crowding the plot. To add a colored background to your plot, insert the following line after the call to plot: # Add this *after* your call to the plot function. rect(par(&quot;usr&quot;)[1], par(&quot;usr&quot;)[3], par(&quot;usr&quot;)[2], par(&quot;usr&quot;)[4], col = &quot;grey90&quot;) Then draw your grid in white: # Add this *after* your call to the rect function. abline(h = seq(0, 0.5, 0.1), v = 0:5, col = &quot;white&quot;) When adding anything to a base R plot, R draws on top of the existing plot. That means it looks more professional if you redraw the points on top of the rest. Your full code for the plot then looks something like this: # Coordinate system: plot( A595 ~ BSA, data = DF, main = &quot;BSA Curve&quot;, xlab = &quot;Protein (μg/ml)&quot;, ylab = bquote(A[595]), las = 1 ) # Background: rect(par(&quot;usr&quot;)[1], par(&quot;usr&quot;)[3], par(&quot;usr&quot;)[2], par(&quot;usr&quot;)[4], col = &quot;grey90&quot;) # Grid: abline(h = seq(0, 0.5, 0.1), v = 0:5, col = &quot;white&quot;) # BSA curve: abline(coef(model), lwd = 2, col = &quot;steelblue&quot;) # Observations redrawn: points(A595 ~ BSA, data = DF, pch = 19) 4.6 Alternative Method (*) It is a bit awkward to first fit a model that predicts the \\(\\text{A}_{595}\\), and then invert the formula to obtain predictions for the amount of protein, like we did with eq. (4.1). Unfortunately, this is the standard procedure in biology. In this optional exercise, you are going to do it the correct way from a statistical point of view: Start from the beginning and fit a linear model where the amount of protein is the outcome, rather than the absorbance (lm(BSA ~ A595, data = DF)); Go through the chapter again, adjusting the code where needed with this inverted model; Does your prediction differ from the previous one? Why do you think that happens? Bradford, Marion (1976): “A Rapid and Sensitive Method for the Quantification of Microgram Quantities of Protein Utilizing the Principle of Protein-Dye Binding”. Analytical Biochemistry. 72 (1–2): 248–254. doi:10.1006/abio.1976.9999. PMID 942051↩︎ The reason the line does not go exactly through zero is because it is only fitted to these 5 observations, which have uncertainty. You could force the line to go through zero, but that would worsen the estimate of the slope.↩︎ Shown on the left are the distances to the mean value of \\(\\text{A}_{595}\\).↩︎ "],["your-own-experiment-i.html", "Chapter 5 Your Own Experiment I 5.1 Introduction 5.2 Study Design 5.3 Why Use a Statistical Test? 5.4 How Do Statistical Tests Work? 5.5 The Chi-Squared Test 5.6 Exercises", " Chapter 5 Your Own Experiment I Date: 10 December 2021 (Microbiology course) Topic: Study design, hypothesis testing Duration: Up to you. In this chapter, I will walk you through the different ways you can setup an experiment that can be analyzed by a \\(\\chi^2\\)-test, or some variant of it. You have already used this test at least once, during the practical on Mendelian genetics. For the purpose of the course, you are free to design your own experiment, but I do recommend you avoid complicating the study design. If you have an idea for an experiment, ask an assistant or your teacher for approval. 5.1 Introduction This is the explanation for first year biology students taking the microbiology course at Leiden University. The portfolio exercise itself is described all the way at the end. The first exercise uses an example data set. In the second exercise, you are to use your own experimental data. 5.2 Study Design In the microbiology assignment, you will design your own experiment, perform an analysis, draw conclusions and report your findings. That is a lot of work, so start planning in time! Designing a study requires consideration of both biology and statistics: What question is the study supposed to answer? What kind of test or model is able to do so? What are the independent experimental units?6 How large should your sample size be? To make it all feasible within the context of your microbiology course, let’s restrict ourselves to one particular kind of comparison: Differences in counts among groups. For example: Is there a difference in the number of bacterial colonies counted on agar plates exposed to the air for an hour in the kitchen and the living room? The experiment then looks something like this: Feel free to come up with your own variation, but ask a course assistant or your teacher whether your research question is valid (and feasible). Also note that a more complex comparison may require a more elaborate study design and analysis! Try and keep it simple. If you stick to bacterial counts in different groups, you can use a \\(\\chi^2\\)-squared test for the analysis, and a single agar plate per group. The \\(\\chi^2\\)-squared test is explained below, using an example data set. 5.3 Why Use a Statistical Test? You could simply count the number of colonies on each plate, determine the differences and be done with it. So what’s the appeal of a statistical test? In the example research question, we compare the number of bacterial colonies after exposure to different conditions (kitchen, living room). There are uncountably many potential influences that we cannot (perfectly) measure, or control. Think of: The amount of medium on each plate will always differ slightly; Temperature, humidity, airflow, and the amount of sunlight cannot be controlled precisely, but can be expected to affect the number of live bacteria falling onto the plate; Storage and transportation conditions can be logically expected to affect growth; Bacteria from your hand or breath might fall onto the plate, rather than bacteria floating in the air of the kitchen/living room; The number of bacteria in the air is likely to depend on the last time someone used the kitchen, the ventilation hood and any nearby windows; Low concentration bacteria in the air either will, or will not enter the plate by chance; You would probably count a different number of bacteria, had you chosen a different moment, or position in the kitchen. And there are many other potential influences. Therefore, the exact count is hardly interesting. We aren’t so much interested in whether there is a difference, but rather whether there is large enough difference to be considered significant. A statistical test can help you decide on this. Ideally, we would use a large number of replicates, so that we are not looking at the effect of a single, outlying observation (e.g. a particularly dirty kitchen). Therefore, in a later chapter we will reflect on the results of all students combined, and how we can best analyze those. 5.4 How Do Statistical Tests Work? A statistical test works by taking on a statement of no difference and then collecting evidence against it. This statement of no difference is called the null-hypothesis (\\(H_0\\)). If there is sufficient evidence against it, the null-hypothesis is rejected. What consitutes ‘enough’ evidence depends on what is considered an acceptable chance of a false positive (\\(\\alpha\\)): Null-hypothesis (\\(H_0\\)): A statement of no difference; Level of significance (\\(\\alpha\\)): What is an acceptable chance of a false positive?7 When counting bacterial colonies on plates from two plates, the null-hypothesis would be: \\(H_0:\\) There is no difference in the number of bacterial colonies on either plate. A false positive would mean that you conclude a significant difference, even though the null-hypothesis is true. This can always happen, because a sample is just a random draw from the population,8 and can coincidentally be different from its population. So which value should you choose for the level of significance (\\(\\alpha\\))? That depends on your research: If we’re developing a diagnostic test for cancer, then a false positive could mean a a very serious operation for the patient. This means we have to be very strict about false positives. Even \\(\\alpha = 0.01\\) would mean \\(\\frac{1}{100}\\) healthy individuals would wrongly undergo treatment;9 If we’re just counting bacteria in kitchens and living rooms, a false positive is not that consequential, and we can be less strict about what is significant. Specifically, that means you could choose whatever value for \\(\\alpha\\) you want. However, in biological journals, it is convention to go no higher than \\(\\alpha = 0.05\\). That implies a chance of \\(5\\%\\), or \\(\\frac{1}{20}\\), of a false positive. Therefore, for this experiment, let’s use: \\(\\alpha = 0.05\\) When we conduct the test, it will result in a \\(p\\)-value. This is the chance that you would draw a sample with this large a difference, if the null-hypothesis were true. In other words, if there is no actual difference in bacteria in the air of your kitchen and living room, then what is the chance that you observed the difference of your experiment? If this chance is extremely small, then we reject the null-hypothesis. Specifically: If \\(p &lt; \\alpha\\), reject \\(H_0\\); If \\(p \\geq \\alpha\\), there is insufficient evidence against \\(H_0\\). An insignificant test does not demonstrate that there is no difference. It just means that your sample provides insufficient reason to reject the null-hypothesis. Nevertheless, the null-hypothesis is still only an assumption. 5.5 The Chi-Squared Test Suppose we do the experiment and count: Kitchen: 21 kolonies; Living room: 15 kolonies. Comparing observed to expected counts can be done with a \\(\\chi^2\\)-test (chi-squared). This test looks whether the proportion of colonies counted on the plate from the kitchen and living room are equal. 5.5.1 How Does the Chi-Squared Test Work? As you’ll see in the next section, performing the test is really easy with chisq.test(). Nevertheless, here I’ll explain what the test actually does, so you can see what it is we’re really doing. If you already know how it works, feel free to skip to the next section. In short: A chi-squared test calculated the number \\(\\chi^2\\) as shown below, and then calculates a corresponding \\(p\\)-value. If the \\(p\\)-value is lower than \\(\\alpha\\), then there is a significant difference in the colonies counted in the kitchen and living room. \\(\\chi^2 = \\displaystyle\\sum_{i = 1}^k \\frac{(\\text{observed} - \\text{expected})^2}{\\text{expected}}\\) The expected numbers are the numbers under the null-hypothesis. These are simply equal to the average count: \\(\\text{expected} = \\frac{21 + 15}{2} = 18\\) Now we can calculate \\(\\chi^2\\): \\(\\chi^2 = \\displaystyle\\sum_{i = 1}^k \\frac{(\\text{obs.} - \\text{exp.})^2}{\\text{exp.}} = \\frac{(\\text{21} - \\text{18})^2}{\\text{18}} + \\frac{(\\text{15} - \\text{18})^2}{\\text{18}} = \\frac{1}{2} + \\frac{1}{2} = 1\\) You don’t have to know how to estimate a \\(p\\)-value from that number, but I can easily show it in a figure: That is the chi-squared distribution with one degree of freedom (because we have two groups and calculated one value). This figure shows the distribution of values of \\(\\chi^2\\) that you would expect to find if the null-hypothesis were true. De largest chance is a value of \\(\\chi^2 = 0\\), and after that, the probability density decreases. The \\(p\\)-value answers the question: If the null-hypothesis is true, what is the chance of our \\(\\chi^2 = 1\\) or higher?. The \\(p\\)-value for \\(\\chi^2=1\\) is the surface area under the probability distribution from \\(1\\) on: That is \\(31.7\\%\\), almost one third of the entire surface area, so we don’t have very convincing evidence against the null-hypothesis: If there is no difference in the population, the chance of \\(\\chi^2 \\geq 1\\) is \\(p = 0.317\\). In this example, \\(p &gt; \\alpha\\), so we don’t reject \\(H_0\\). In the report we would write that there is insufficient evidence to conclude a difference in bacteria in the kitchen and living room from this experiment. To calculate this value yourself, you would have to evaluate the integral of the chi-squared distribution from \\(1\\) to \\(\\infty\\). I don’t recommend trying it by hand. Fortunately, we have R: 1 - pchisq(1, df = 2 - 1) # df: two groups, one value estimated, so 2 - 1 ## [1] 0.3173105 This says: \\(1\\) minus the chance of any value up till \\(\\chi^2=1\\). And that is how we get \\(0.317\\). 5.5.2 Chi-Squared Test in R If you think the explanation so far is a lot, I don’t blame you. It takes quite a lot of background knowledge to understand a simple test. The explanation of how the chi-squared test works will not be part of the microbiology exam. Nevertheless, I wanted to include it here, so that you can read what is going on when you use this test. Namely, it can all be done in a few seconds in R: example &lt;- c(21, 15) chisq.test(example) ## ## Chi-squared test for given probabilities ## ## data: example ## X-squared = 1, df = 1, p-value = 0.3173 That is all there is to it: R calculated a value of \\(\\chi^2 = 1\\); It then says df = 1, which means there is one degree of freedom: \\(\\text{number of independent observations} - \\text{number of estimated parameters} = 2 - 1 = 1\\); Those things combined yield a \\(p\\)-value of 0.3173. 5.6 Exercises Open the R markdown file “Exercises.Rmd” and answer the questions. The questions themselves are included here. 5.6.1 Performing a Chi-Squared Test Suppose another student performs the same experiment and counts: Kitchen: 36 colonies; Living room: 21 colonies. Use \\(\\alpha = 0.05\\) and conduct a \\(\\chi^2\\)-test for these data. You can use the code above and adapt it. 5.6.2 Comparing Two Students Suppose we want to see if the counts are significantly different between two students: Table 5.1: \\(2 \\times 2\\) contingency table of student 1 &amp; 2. Kitchen Living room Student 1 21 15 Student 2 36 21 All a \\(\\chi^2\\)-test does is compare observed to expected counts. You can apply this to contingency tables too. The test then determines the difference in the proportion of colonies in the kitchen and living room for student 1 and 2. You don’t have to calculate the expected counts by hand, but an explanation is given below for those interested.\\(^\\dagger\\) In R, all you have to do is put the data in a \\(2 \\times 2\\) matrix, for example using rbind (row bind): Student1 &lt;- c(21, 15) Student2 &lt;- c(36, 21) ContingencyTable &lt;- rbind(Student1, Student2) # Create a 2x2 matrix colnames(ContingencyTable) &lt;- c(&quot;Kitchen&quot;, &quot;Living Room&quot;) # Add column names ContingencyTable # Print the result ## Kitchen Living Room ## Student1 21 15 ## Student2 36 21 Then, simply use chisq.test() on the contingency table: chisq.test(ContingencyTable) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: ContingencyTable ## X-squared = 0.060876, df = 1, p-value = 0.8051 This results in a \\(p\\)-value for the null-hypothesis: The difference in kitchen and living room is independent of which student performs the experiment. With \\(\\alpha = 0.05\\), what would you conclude? \\(^\\dagger:\\) For a contingency table, the expected counts are what you would expect if the relative counts of student 1 did not differ from student 2, proportional to their total counts: Table 5.2: Observed and expected frequencies for a \\(2 \\times 2\\) contingency table. Observed Expected Kitchen Living room Kitchen Living room Student 1 21 15 \\(\\frac{(21+36)(21+15)}{21+36+15+21}\\) \\(\\frac{(15+21)(21+15)}{21+36+15+21}\\) Student 2 36 21 \\(\\frac{(21+36)(36+21)}{21+36+15+21}\\) \\(\\frac{(15+21)(36+21)}{21+36+15+21}\\) 5.6.3 Comparing Two Other Students Conduct the same test for the difference between two students using the real experimental data from your class. For example, you could compare the results with your lab partner’s. You can use the the previous exercise as an example. An experimental unit is the smallest division of the sample that is still an independent part. Some example: In clinical trials, patients are experimental units; In a study on fertilizer effectiveness, plants are experimental units; In an experiment on antibiotic effectiveness, a single agar plate is an experimental unit.↩︎ A false positive occurs when you conclude a significant difference, even though there is no real difference in the underlying population from which the sample came. Example 1: If we conclude a medicine works significantly better than a placebo in the sample, but it does not actually work on average in the population, then we have a false positive for the effect of the medicine. Example 2: Say we estimate the ratio of black to white sheep in a large farm by drawing a random sample. A false postive would occur if in the sample, the ratio differed significantly from \\(1 : 1\\), even though it does not in the whole farm. False positives are also called type I errors.↩︎ The population here consists of all possible samples of air from your kitchen and living room.↩︎ Of course, in reality a diagnostic test for cancer is followed by further diagnosis to minimize the probability of this scenario.↩︎ "],["sepia.html", "Chapter 6 Sepia 6.1 Getting Started 6.2 Creating a Subset 6.3 Data Cleaning 6.4 Plotting the Data 6.5 T-test", " Chapter 6 Sepia Date: 16/17 March 2022 (Animal Biodiversity course) Topic: Data manipulation, \\(t\\)-test (tutorial ) Duration: 60–90 minutes Does the common cuttlefish (Sepia officinalis) display sexual dimorphism? Are males perhaps taller or wider? In this chapter, you are going to scientifically compare two groups of measurements. 6.1 Getting Started The first step is to correctly read your data into the software: If you haven’t already, install RStudio; Download the data. If it is an Excel (.xlsx) file, open it in Excel and save as CSV; Open RStudio and create a new R markdown file. Save this file to the same folder as the data! Go to Session &gt; Set Working Directory &gt; To Source File Location. R now knows where to locate your data; Create a new code chunk and run the following: Sepia &lt;- read.csv(&quot;Sepia.csv&quot;) (This only works for CSV files. If it doesn’t work, you probably have a Dutch version of Excel, in which case read.csv2() should work instead.) This requires that your CSV file is also called “Sepia”. From here on out, just read the text, run the code in R, adjust the R code if needed, and answer the questions. If you can’t find the data on Brightspace, you can download it here (make sure to rename it from “Sepia2223.csv” to “Sepia.csv”). If the code ran successfully, you will have an object called Sepia in your workspace. You can view it by clicking it, or by running: View(Sepia) Does R understand which variables are numbers and which are something else? Let’s check: str(Sepia) ## &#39;data.frame&#39;: 174 obs. of 6 variables: ## $ Group : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Student: int 1 2 3 4 5 6 7 8 9 10 ... ## $ Sex : chr &quot;male&quot; &quot;&quot; &quot;female&quot; &quot;&quot; ... ## $ Length : num 22.5 NA 20 NA NA 22 NA 17 NA 12 ... ## $ Width : num 17 NA 17 NA NA 16 NA 16 NA 8 ... ## $ Comment: chr &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ... Question: Is the data read correctly into R? How can you tell? What do you think chr and int mean? 6.2 Creating a Subset We just read the whole data set. It contains the data from both groups. Let’s make a subset of the measurements performed by your group: Subset &lt;- Sepia[Sepia$Group == 1, ] (If you are in Group B, change 1 to 2.) What does this code do? Subset &lt;-: Create a object named Subset; Sepia[x, y]: From the data set Sepia, select only rows x and columns y. If y is left blank, it selects all columns;10 Sepia$Group == 1: From the data set Sepia, select the variable Group and check if it is equal to the value 1 (TRUE) or not (FALSE). Did that work? You can check by comparing the number of rows in both objects: nrow(Sepia) ## [1] 174 nrow(Subset) ## [1] 94 That number should match the number of students in your group. 6.3 Data Cleaning Usually this is where you would have to spend considerable time fixing small mistakes in the data, like some students typing “male” (lowercase), others “Male” (uppercase), etc. Fortunately for you, in this year’s version the data has already undergone some precleaning. There is, however, one suspicious thing still going on in the data. Namely, a lot observations appear duplicated! See for example the following rows: Sepia[105:110, ] # Print rows 105 to 115 ## Group Student Sex Length Width Comment ## 105 2 11 female 21.0 19 ## 106 2 12 female 21.0 19 ## 107 2 13 male 16.5 14 ## 108 2 14 male 16.5 14 ## 109 2 15 female 12.5 10 ## 110 2 16 female 12.5 10 I’m assuming what happened is that students worked in pairs 1–2, 3–4, 5–6, etc., which appears to be the case if you inspect the data. There are different ways to fix this: Remove all duplicated length-width-sex combinations; (not safe, real duplicates are possible due to rounding, and some pairs both measured the same Sepia with different measurement error) Choose on a case-by-case basis; (safest, but tedious) For every student pair, average the results, omitting empty rows. (safe if my assumptions about student pairs is correct and there is an even number of students) Here is how you could do that (choose one option): Remove all duplicates # Remove all duplicates (easiest, but not safe): Cleaned &lt;- Subset[!duplicated(Subset[, c(&quot;Sex&quot;, &quot;Length&quot;, &quot;Width&quot;)]), ] Select manually # Select manually (oh man... good luck) keep &lt;- c(1, 2, 6, 8) # add as many as you like/trust Cleaned &lt;- Subset[keep, ] Average per student pair (This requires some more code.) # 1. Use the modulo operator to find odd and even odd &lt;- (1:nrow(Subset) %% 2) == 1 even &lt;- (1:nrow(Subset) %% 2) == 0 # 2. Create a copy of the data with only the odd rows Cleaned &lt;- Subset[odd, ] # 3. Fill in empty values for sex with the even ones odd_sex &lt;- Subset$Sex[even] Cleaned$Sex[Cleaned$Sex == &quot;&quot;] &lt;- odd_sex[Cleaned$Sex == &quot;&quot;] # 4. Create an object with pairs next to each other (column bind) paired &lt;- cbind(Subset$Length[odd], Subset$Length[even]) # 5. Average the odd and even lengths (applies the function &#39;mean&#39; to each row) Cleaned$Length &lt;- apply(paired, 1, mean, na.rm = TRUE) # 6. Do the same for Width paired &lt;- cbind(Subset$Width[odd], Subset$Width[even]) Cleaned$Width &lt;- apply(paired, 1, mean, na.rm = TRUE) # 7. NaN (not a number) can give problems later on, # let&#39;s convert that to NA (not available) instead Cleaned$Length[is.nan(Cleaned$Length)] &lt;- NA Cleaned$Width[is.nan(Cleaned$Width)] &lt;- NA # 8. Remove empty rows (select rows where Sex is not empty) Cleaned &lt;- Cleaned[Cleaned$Sex != &quot;&quot;, ] Choose one of the three methods above to create a cleaned version. Describe briefly (1–2 sentences) which method you chose and why. 6.4 Plotting the Data Just looking at code and numbers is a bit stale. So let’s make some relevant plots: par(mfrow = c(2, 2)) # Plot in a 2x2 grid hist(Cleaned$Length, col = &quot;lightgray&quot;) hist(Cleaned$Width, col = &quot;lightgray&quot;) plot(Length ~ Width, data = Cleaned, col = factor(Sex), pch = 1) boxplot(Width ~ Sex, data = Cleaned, col = c(&quot;blue&quot;, &quot;orange&quot;)) par(mfrow = c(1, 1)) # Restore the default Question: What does each plot show? Can you change the code to alter the figures? (You can try changing the variable names, or change the graphical parameters.) 6.5 T-test How do we compare measurements of two groups? One way to do that is through a \\(t\\)-test. To choose the right \\(t\\)-test, you should understand five choices: Do you need a one-sample, or two-sample \\(t\\)-test? Do you want to test one-sided or two-sided? Is it reasonable to assume equal variance? Are the measurements independent or paired? Is the underlying assumption of normality reasonable? Do you remember all of those choices? Is so, impressive! If not, you can rewatch the video version of the lecture here: 6.5.1 Example Below is an example of a \\(t\\)-test, using some standard data in R: t.test(extra ~ group, data = sleep, alternative = &quot;less&quot;, var.equal = TRUE) ## ## Two Sample t-test ## ## data: extra by group ## t = -1.8608, df = 18, p-value = 0.03959 ## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0 ## 95 percent confidence interval: ## -Inf -0.1076222 ## sample estimates: ## mean in group 1 mean in group 2 ## 0.75 2.33 This particular \\(t\\)-test is a one-sided \\(t\\)-test for equal variance. Here’s how to interpret the output: The mean of group 1 is \\(0.75\\) hours of extra sleep, while the mean of group 2 is \\(2.33\\). The \\(p\\)-value for this test is \\(0.0396\\). If we use a level of significance of \\(\\alpha = 0.05\\), then group 2 is has a significantly larger mean than group 1, because \\(0.0396 &lt; 0.05\\). 6.5.2 Exercise Question: Choose a \\(t\\)-test you deem appropriate for: Comparing male and female length; Comparing male and female width. (They could be the same, just explain briefly why you chose a certain \\(t\\)-test.) Question: Perform the tests you chose for (1) and (2) in R and draw a conclusion. Have a look at how the example was coded using the data argument and adjust it to make it work for the data of your group (Cleaned). You may use the same level of significance \\(\\alpha = 0.05\\). Did we now prove that Sepia males and females differ in physical dimensions? Did we prove they are the same? What is the right way to express the conclusion? Adapt the code from 6.2 to create a subset of your table only. Compare your results with at least one other table. If your conclusion differs, can you explain why? (Optional) You performed two tests. That means that both can result in a false positive. With \\(\\alpha = 0.05\\), what is the chance of at least one false positive when performing two tests? Whenever you see square brackets in R, just think of them as “where”. A data frame has both rows and columns, so for example X[1, 1] means row 1, column 1. X[1, ] means row 1, all columns, and X[, 1] means all rows, column 1.↩︎ "],["your-own-experiment-ii.html", "Chapter 7 Your Own Experiment II 7.1 Study Design 7.2 Preparing Your Presentation", " Chapter 7 Your Own Experiment II Date: End of the academic year (late June, EBG course) Topic: Study design, hypothesis testing Duration: Up to you. If you’ve completed the rest of the portfolio, you have now used a \\(\\chi^2\\)-test, a \\(t\\)-test and even simple linear regression at least once. You should also have had your first statistics course by now. Designing a study is all about performing experiments and collecting their data, such that you can perform an analysis that can satisfactorily answer your research question. Hence, the more you know about statistics, the more complicated questions you are able to tackle. For the purpose of this project, I recommend that you design your experiments around a technique you are already familiar with. For instance: A comparison of frequencies (\\(\\chi^2\\)-test); A comparison of two group means (\\(t\\)-test); A comparison of more than two group means (ANOVA); Estimating a linear relationship between two continuous variables (simple linear regression). During the EGB project, I will give a lecture about what to do and what avoid when designing your study. There will also be a Q&amp;A about analyzing your data. For the biostatistics portfolio, there are no further exercises in this chapter. There will be a statistician among the jury of the project presentations, who will judge the analysis of your experiments and the interpretation of the results. 7.1 Study Design Click here to be redirected to the E-learning module on study design. 7.2 Preparing Your Presentation Click here to be redirected to the E-learning module on presenting. "],["adding-figures-in-r-markdown.html", "Adding Figures in R Markdown Image from a File (simple) Image from a File (advanced) Plots Drawn in R", " Adding Figures in R Markdown This chapter is optional. I may refer to it elsewhere as a reference guide for adding plots and figures in R markdown. In this chapter you will learn how to insert a figure in an R markdown (.Rmd) file. You can use this chapter as future reference for when you want to include figures in later chapters. Image from a File (simple) The simplest way to include a figure is by writing anywhere outside code chunks (in the white space): ![description](path/to/image.extension) In case the image is saved in the same folder as your R markdown file, this simplifies to: ![description](image.extension) (Replace image by the name of your file. Replace extention by whatever file extension your image has, like JPG, PNG or BMP.) This method is fine when you just want to include an image as is and don’t care about anything else. For example, in the folder of my R markdown file, I have a subfolder figures with an example image called pollenSEM.jpg. Writing ![Some description](figures/pollenSEM.jpg) will include this image with a caption: An image of pollen under an SEM. From: https://w.wiki/gv8 Exercise 1 Include an image of your liking to your R markdown file using the method described above. For your own convenience, I recommend saving both the Rmd file and the image in the same folder. Knit your file to see if the image renders correctly. If you want to resize the image, check the next section. Image from a File (advanced) For greater flexibility, include figures using include_graphics(). To use this function, you have to place it in a code chunk. For example: ```{r label = pollen, echo = TRUE, fig.cap = &quot;Image of pollen under an SEM. From: https://w.wiki/gv8&quot;, out.width = &#39;20%&#39;} knitr::include_graphics(&quot;figures/pollenSEM.jpg&quot;) ``` Figure 7.1: Image of pollen under an SEM. From: https://w.wiki/gv8 Here I have set echo = TRUE, so that you can see the code that produced the figure. Usually, you will want to hide this code in a report. You can set echo = FALSE to suppress code in the output. (For those interested, a comprehensive list of chunk options is described here.) Adding a caption with the fig.cap argument automatically numbers the image. In addition, it allows for cross-referencing, using \\@ref(fig:...). Simply replace ... with the label you wrote for the chunk containing the image. For example, if I write \\@ref(fig:pollen), you will see: Figure 7.1. The 3 here refers to the chapter number and .1 refers to the first image in this chapter. Exercise 2 Using the advanced method, insert your figure from exercise 1 with a smaller size, using a new code chunk. Then, add a sentence below the chunk referencing the image using \\@ref(fig:...). Plots Drawn in R Of course, you can also include plots generated by R code. Below are some examples. Simple Example (Linear Relationship) x &lt;- 0:10 y &lt;- -5 + 2 * x plot(y ~ x, type = &quot;l&quot;, main = &quot;Linear Relationship&quot;) Figure 7.2: A linear relationship You can change the \\(x\\) and \\(y\\) axis range by using xlim and ylim, respectively: x &lt;- 0:10 y &lt;- -5 + 2 * x plot(y ~ x, type = &quot;l&quot;, main = &quot;Linear Relationship&quot;, xlim = c(0, 7.5), ylim = c(0, 10)) Figure 7.3: A linear relationship In fact, you can change virtually anything about the plot. You may skip this part if that doesn’t interest you. We will go into detail about this later in the portfolio, but here is a quick example: x &lt;- 0:10 y &lt;- -5 + 2 * x plot( y ~ x, # Where to plot type = &quot;b&quot;, # What to plot (both points and linepieces) main = &quot;Custom plot&quot;, # Title ylab = &quot;y-values&quot;, # Y-label xlab = &quot;x-values&quot;, # X-label font = 2, # Axis font (bold) pch = 19, # Point character (solid) cex = 2, # Character expansion factor lty = &quot;dashed&quot;, # Line type lwd = 3, # Line width las = 1, # Perpendicular axes bty = &quot;n&quot;, # No box around the plot col = &quot;steelblue&quot;, # Change the color of what is plotted col.main = &quot;darkblue&quot;, # Color of the title col.lab = &quot;gray&quot;, # Color of the labels col.axis = &quot;darkgray&quot;, # Color of the axes ) Figure 7.4: A linear relationship If you like changing plots, you can find many more settings in the help page for par. Multiple Plots in One Area You can also add multiple plots to a single plotting area, using par: par(mfrow = c(2, 3)) # Two rows and three columns (6 plots) plot(Sepal.Length ~ Sepal.Width, data = iris, main = &quot;Sepal Length vs Sepal Width&quot;) plot(Sepal.Length ~ Petal.Length, data = iris, main = &quot;Sepal Length vs Petal Length&quot;) plot(Sepal.Length ~ Petal.Width, data = iris, main = &quot;Sepal Length vs Petal Width&quot;) plot(Sepal.Width ~ Petal.Length, data = iris, main = &quot;Sepal Width vs Petal Length&quot;) plot(Sepal.Width ~ Petal.Width, data = iris, main = &quot;Sepal Width vs Petal Width&quot;) plot(Petal.Length ~ Petal.Width, data = iris, main = &quot;Petal Length vs Petal Width&quot;) par(mfrow = c(1, 1)) # Restore the default (1 plot) Figure 7.5: Four variables in the iris data set plotted against each other. Here I used par(mfrow = c(2, 3)) to create a grid of 2 by 3 plots. I had to include the data argument to tell R where to retrieve these variables (a standard data set in R). I included the last line to restore the default settings. If you ever change a setting and forget the default, either look at the par help page, or just restart RStudio. Exercise 3 The code below generates data for a logarithmic, exponential and quadratic relationship. x &lt;- seq(1, 10, 0.01) y1 &lt;- -5 + 2 * log(x) y2 &lt;- -5 + 2 * exp(x) y3 &lt;- -5 + 2 * x^2 Copy the code above to a new chunk in your Rmd file and plot x against y1.\\(^\\dagger\\) Then create two more plots, where you plot x against y2 and x against y3. Use par(mfrow = c(..., ...)) to arrange these plots side by side. Within each call to plot, use the main argument to give each plot a title. Feel free to try and adjust other graphical parameters! \\(^\\dagger:\\) You don’t need the data argument here, because if you run the code above, the objects will be stored in the workspace. Exercise 4 (*) For those seeking an extra challenge, let’s create a plot of a bacterial growth curve: First, there is a lag phase where no growth is observed; Then, growth enters an exponential phase; At some point, space and resource scarcity kick in and growth slows down to a stationary phase (no growth); Finally, resources are slowly, but surely exhausted and a negative growth takes place (death phase). Create a plot that shows each of the four phases. You can use the function lines to draw separate pieces of the curve, if you find that easier. Exercise 5 (*) Use the function text to add the name of each phase above the plot. Adjust ylim if you have insufficient space for text, and set the cex argument in the text function to something smaller than 1 if the text does not fit. "],["adding-tables-in-r-markdown.html", "Adding Tables in R Markdown The User-Friendly Way: kable Advanced: xtable (*)", " Adding Tables in R Markdown This chapter is optional. I may refer to it elsewhere as a reference guide for adding tables in R markdown. In this chapter you will learn how to insert a table in an R markdown (.Rmd) file. You can use this chapter as future reference for when you want to include tables in later chapters. The User-Friendly Way: kable Suppose you want to include a correlation matrix of the numeric variables in your data set: cor(iris[, -5]) # Omit the categorical column 5 (Species) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411 ## Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259 ## Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654 ## Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000 This is fine if you just want to see the correlation matrix yourself, but in a report you would want to change this into something more presentable. A fairly straightforward function for including tables is kable. It is part of the knitr package that you use to knit files. Compare the correlation matrix above with the one below: library(&quot;knitr&quot;) # Load the functions in knitr, including kable() kable(cor(iris[, -5])) Sepal.Length Sepal.Width Petal.Length Petal.Width Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411 Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259 Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654 Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000 That’s it! Just wrap kable() around it and knitr will create a decently formatted table in the output. This works identically for knitting to Word, HTML or PDF. We can improve the table. For starters, it is hard to justify 7 decimals, so let’s change that to 2: M &lt;- cor(iris[, -5]) # Store the correlation matrix into an object M kable(round(M, 2)) # Round to 2 decimals Sepal.Length Sepal.Width Petal.Length Petal.Width Sepal.Length 1.00 -0.12 0.87 0.82 Sepal.Width -0.12 1.00 -0.43 -0.37 Petal.Length 0.87 -0.43 1.00 0.96 Petal.Width 0.82 -0.37 0.96 1.00 We can also change the periods (.) in the variable names into spaces: M &lt;- cor(iris[, -5]) rownames(M) &lt;- c(&quot;Sepal Length&quot;, &quot;Sepal Width&quot;, &quot;Petal Length&quot;, &quot;Petal Width&quot;) colnames(M) &lt;- c(&quot;Sepal Length&quot;, &quot;Sepal Width&quot;, &quot;Petal Length&quot;, &quot;Petal Width&quot;) kable(round(M, 2)) Sepal Length Sepal Width Petal Length Petal Width Sepal Length 1.00 -0.12 0.87 0.82 Sepal Width -0.12 1.00 -0.43 -0.37 Petal Length 0.87 -0.43 1.00 0.96 Petal Width 0.82 -0.37 0.96 1.00 Or we could do it automatically with the function gsub (useful for larger data sets): M &lt;- cor(iris[, -5]) rownames(M) &lt;- gsub(&quot;[.]&quot;, &quot; &quot;, rownames(M)) # Exchange the period with a space colnames(M) &lt;- gsub(&quot;[.]&quot;, &quot; &quot;, colnames(M)) # Exchange the period with a space kable(round(M, 2)) (Output omitted; Identical to the previous table.) Finally let’s center the numbers and add a caption: kable(round(M, 2), align = &quot;cccc&quot;, caption = &quot;A correlation matrix of the iris data set.&quot;) Table 7.1: A correlation matrix of the iris data set. Sepal Length Sepal Width Petal Length Petal Width Sepal Length 1.00 -0.12 0.87 0.82 Sepal Width -0.12 1.00 -0.43 -0.37 Petal Length 0.87 -0.43 1.00 0.96 Petal Width 0.82 -0.37 0.96 1.00 (For those interested, a comprehensive list of formatting options with kable can be found here.) Exercise 1 Make a table of the first 10 observations in the iris data set using kable. Remember to use library(\"knitr\") to load the kable function. Center all the variables. Knit your R markdown file to see if it renders correctly. Exercise 2 (*) For those seeking an extra challenge, create a table that shows the mean (mean) and standard deviation (sd) of each numeric variable, per species. Advanced: xtable (*) The package xtable allows for far more control over the formatting. If you want to write professional looking reports in PDF format using R markdown, I recommend familiarizing yourself with xtable. There are no exercises for this paragraph. You may skip this part entirely if you’re fine with just kable. To install and load xtable, run: install.packages(&quot;xtable&quot;) library(&quot;xtable&quot;) Then, it works like this: Example &lt;- cor(iris[, -5]) Xtable &lt;- xtable(Example, caption = &quot;A correlation matrix of the iris data set.&quot;) align(Xtable) &lt;- &quot;lcccc&quot; print(Xtable, comment = FALSE, type = &quot;html&quot;) A correlation matrix of the iris data set. Sepal.Length Sepal.Width Petal.Length Petal.Width Sepal.Length 1.00 -0.12 0.87 0.82 Sepal.Width -0.12 1.00 -0.43 -0.37 Petal.Length 0.87 -0.43 1.00 0.96 Petal.Width 0.82 -0.37 0.96 1.00 Note: xtable tables only print when you add the chunk option results = \"asis\". Here we already see some of the advantages and disadvantages of xtable: It requires more code; It does not automatically label the table; It places the caption below the table by default (a matter of preference); It automatically tries to use a sensible number of digits; It allows separate alignment of the rownames (that’s what the l in lcccc does). The main power of xtable does not lie in its HTML features, but rather the precise control over tables in \\(\\LaTeX\\). If you want to create professional looking tables in PDF format, have a look at the xtable gallery. Specific examples can be provided per request. Exercise 3 (*) Create a PDF file containing the table you made in exercise 2, using the xtable function. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
